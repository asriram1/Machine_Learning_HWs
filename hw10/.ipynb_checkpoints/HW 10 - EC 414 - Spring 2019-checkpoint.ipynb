{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HW 10 - EC 414 - Prof. Kulis - Spring 2019**\n",
    "\n",
    "Due Wednesday, May 1st, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Universal approximation power of ReLU networks\n",
    "\n",
    "A two layer NN with sigmoid activation function is a universal approximator, i.e: with sufficient hidden units, it can approximate any real function with desired accuracy. In this problem we want to demonstrate universal approximation power of NNs using ReLU activation units.\n",
    "\n",
    "**Q1.1** Show that by composing only 2 hidden units in a ReLU network $-\\sum_{i=1}^2a_i\\ max(0,b_ix+c_i) -$ we can build an approximation to the step function $1[x>0]$.  Write some code to showcase this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2** Write some code to show that by composing 4 hidden units in a ReLU network, we can build an approximation to the unit impulse function of duration $\\delta$\n",
    "\n",
    "\\begin{equation}\n",
    "u_\\delta(x) = 1[0\\leq x\\leq \\delta]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.3** Using your approximator for the unit impulse function in Q1.2, write code to draw the approximator for different duration values $\\delta = [1,0.5,0.1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Part 1\n",
    "def relu(x):\n",
    "    y = max(0,x) -max(0, x - 1)\n",
    "    rand = 0\n",
    "    if(y > 0):\n",
    "        rand = 1\n",
    "        return rand\n",
    "    else:\n",
    "        return rand\n",
    "\n",
    "delta = [1, 0.5, 0.1]\n",
    "x = np.arange(-2, 2.1, 0.01) \n",
    "x[200] = 0\n",
    "\n",
    "y1 = [0]*410\n",
    "for i in range(410):\n",
    "    y1[i] = (relu(x[i]) - relu(x[i] - (delta[0])) )\n",
    "y2 = [0]*410\n",
    "for i in range(410):\n",
    "    y2[i] = (relu(x[i]) - relu(x[i] - (delta[1])) )\n",
    "y3 = [0]*410\n",
    "for i in range(410):\n",
    "    y3[i] = (relu(x[i]) - relu(x[i] - (delta[2])) )\n",
    "    \n",
    "          \n",
    "for i in range(len(y1)):\n",
    "    if(y1[i] != 1):\n",
    "        y1[i] = 0\n",
    "    if(y2[i] != 1):\n",
    "        y2[i] = 0\n",
    "    if(y3[i] != 1):\n",
    "        y3[i] = 0\n",
    "\n",
    "#x_axis = np.linspace(-2,2, 41)\n",
    "#print(x_axis)\n",
    "plt.plot(x,y1,'b')\n",
    "plt.plot(x,y2,'y')\n",
    "plt.plot(x,y3,'g')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Backprop in a simple MLP\n",
    "Here, we ask you to derive all the steps of the backpropagation algorithm for a simple classification network. Consider a fully-connected neural network, also known as a multi-layer perceptron (MLP), with a single hidden layer and a one-node output layer. The hidden and output nodes use an elementwise sigmoid activation function and the loss layer uses cross-entropy loss:\n",
    "<p>\n",
    "$f(z)=\\frac{1}{1+exp(-z))}$\n",
    "<br>\n",
    "$L(\\hat{y},y)=-yln(\\hat{y}) - (1-y)ln(1-\\hat{y})$\n",
    "</p>\n",
    "<p>\n",
    "The computation graph for an example network is shown below. Note that it has an equal number of nodes in the input and hidden layer (3 each), but, in general, they need not be equal. Also, to make the application of backprop easier, we show the <i>computation graph</i> which shows the dot product and activation functions as their own nodes, rather than the usual graph showing a single node for both.\n",
    "</p>\n",
    "\n",
    "<img src=\"mlpgraph.png\" style=\"height:200px;\">\n",
    "\n",
    "The backpropagation algorithm for an MLP is displayed below. For simplicity, we will assume no regularization on the weights, so you can ignore the terms involving $\\Omega$. The forward step is: \n",
    "\n",
    "<img src=\"forward.png\" style=\"width:500px;\">\n",
    "\n",
    "and the backward step is:\n",
    "\n",
    "<img src=\"backward.png\" style=\"width:500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down each step of the backward pass explicitly for all layers, i.e. for the loss and $k=2,1$, compute all gradients above, expressing them as a function of variables $x, y, h, W, b$. <i>Hint: you should substitute the updated values for the gradient $g$ in each step and simplify as much as possible.</i>  Specifically, compute the following (we have replaced the superscript notation $u^{(i)}$ with $u^i$):\n",
    "\n",
    "**Q2.1**: $\\nabla_{\\hat{y}}L(\\hat{y},y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.2**: $\\nabla_{a^2}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.3**: $\\nabla_{b^2}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.4**: $\\nabla_{W^2}J$ <br><i>Hint: this should be a vector, since $W^2$ is a vector. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.5**: $\\nabla_{h^1}J$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.6**: $\\nabla_{b^1}J$, $\\nabla_{W^1}J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.7** Briefly, explain how would the computational speed of backpropagation be affected if it did not include a forward pass?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
